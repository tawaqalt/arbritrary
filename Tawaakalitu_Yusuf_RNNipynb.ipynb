{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tawaqalt/arbritrary/blob/master/Tawaakalitu_Yusuf_RNNipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kBZ1KSVStyNu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 1] Simple Forward propagation implementation of RNN"
      ],
      "metadata": {
        "id": "s-5Qk1bit1x1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBddIq-WtokR",
        "outputId": "93a65a94-f277-46e6-d5f5-526bbea2178a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: (8, 10, 3)\n",
            "Output: [[[0.53138623 0.2340954  0.23451837]\n",
            "  [0.48396964 0.07434351 0.44168685]\n",
            "  [0.16778918 0.65305308 0.17915774]\n",
            "  [0.00934986 0.56317364 0.4274765 ]\n",
            "  [0.53254342 0.17195434 0.29550223]\n",
            "  [0.94803445 0.01628455 0.03568099]\n",
            "  [0.32338651 0.38120933 0.29540416]\n",
            "  [0.02444282 0.44281166 0.53274552]\n",
            "  [0.02777117 0.19904281 0.77318602]\n",
            "  [0.42607923 0.04980206 0.52411871]]\n",
            "\n",
            " [[0.67308638 0.2983584  0.02855522]\n",
            "  [0.08096381 0.78407558 0.13496061]\n",
            "  [0.40309722 0.11614018 0.4807626 ]\n",
            "  [0.23906978 0.27527045 0.48565977]\n",
            "  [0.18325098 0.0392981  0.77745092]\n",
            "  [0.64451104 0.04279153 0.31269744]\n",
            "  [0.11626363 0.62829042 0.25544595]\n",
            "  [0.01543592 0.65266214 0.33190195]\n",
            "  [0.02039204 0.61543278 0.36417518]\n",
            "  [0.12937254 0.09316449 0.77746297]]\n",
            "\n",
            " [[0.43550137 0.52659589 0.03790274]\n",
            "  [0.01132484 0.65263177 0.3360434 ]\n",
            "  [0.04157398 0.20251915 0.75590687]\n",
            "  [0.65460274 0.02604642 0.31935084]\n",
            "  [0.48243091 0.08182255 0.43574653]\n",
            "  [0.0163113  0.65794073 0.32574797]\n",
            "  [0.21309301 0.76412214 0.02278486]\n",
            "  [0.92232605 0.05124775 0.0264262 ]\n",
            "  [0.03623216 0.81018333 0.15358451]\n",
            "  [0.60188186 0.37278932 0.02532882]]\n",
            "\n",
            " [[0.05102759 0.06293243 0.88603998]\n",
            "  [0.04822    0.02760259 0.92417741]\n",
            "  [0.95150265 0.02600491 0.02249244]\n",
            "  [0.05481916 0.01677538 0.92840547]\n",
            "  [0.06392372 0.03958807 0.89648821]\n",
            "  [0.94956485 0.02189099 0.02854416]\n",
            "  [0.0500246  0.85614147 0.09383393]\n",
            "  [0.00856285 0.62423578 0.36720137]\n",
            "  [0.27959925 0.68896374 0.031437  ]\n",
            "  [0.60700306 0.02640849 0.36658845]]\n",
            "\n",
            " [[0.89020281 0.07567154 0.03412565]\n",
            "  [0.28194626 0.50232895 0.21572479]\n",
            "  [0.63140824 0.33308472 0.03550704]\n",
            "  [0.01381494 0.60839312 0.37779194]\n",
            "  [0.9153243  0.0266519  0.0580238 ]\n",
            "  [0.42859731 0.18304403 0.38835866]\n",
            "  [0.08033596 0.791972   0.12769204]\n",
            "  [0.90303523 0.06293587 0.0340289 ]\n",
            "  [0.05744697 0.44227713 0.5002759 ]\n",
            "  [0.56750713 0.0400694  0.39242347]]\n",
            "\n",
            " [[0.08366943 0.30530026 0.61103032]\n",
            "  [0.14434877 0.25109549 0.60455574]\n",
            "  [0.74528412 0.0395003  0.21521558]\n",
            "  [0.0707229  0.65009254 0.27918457]\n",
            "  [0.89563141 0.07182224 0.03254636]\n",
            "  [0.06489212 0.9028609  0.03224698]\n",
            "  [0.62891929 0.34622356 0.02485715]\n",
            "  [0.21133962 0.72875664 0.05990373]\n",
            "  [0.0097169  0.56865864 0.42162446]\n",
            "  [0.46081192 0.17773077 0.36145731]]\n",
            "\n",
            " [[0.01577663 0.45248143 0.53174194]\n",
            "  [0.02653924 0.24072812 0.73273264]\n",
            "  [0.58233797 0.04754959 0.37011244]\n",
            "  [0.02019076 0.3192946  0.66051464]\n",
            "  [0.05394522 0.01827891 0.92777587]\n",
            "  [0.96438998 0.01451516 0.02109485]\n",
            "  [0.44641041 0.14615156 0.40743803]\n",
            "  [0.00929508 0.5899939  0.40071102]\n",
            "  [0.23679214 0.42457346 0.3386344 ]\n",
            "  [0.9583332  0.0178609  0.0238059 ]]\n",
            "\n",
            " [[0.16726576 0.38197123 0.45076301]\n",
            "  [0.05775035 0.05917706 0.88307259]\n",
            "  [0.24921678 0.02222291 0.72856031]\n",
            "  [0.2861718  0.05709229 0.6567359 ]\n",
            "  [0.04652039 0.3716166  0.58186302]\n",
            "  [0.63300708 0.2964707  0.07052221]\n",
            "  [0.00816349 0.61505155 0.37678496]\n",
            "  [0.04612703 0.77001563 0.18385734]\n",
            "  [0.96590934 0.01413681 0.01995385]\n",
            "  [0.95518807 0.01695231 0.02785962]]]\n"
          ]
        }
      ],
      "source": [
        "class ScratchSimpleRNNClassifier:\n",
        "  #initializing parameters\n",
        "    def __init__(self, n_features, n_nodes, n_output, n_sequences, lr=0.01, random_state=None):\n",
        "        np.random.seed(random_state)\n",
        "        self.n_features = n_features\n",
        "        self.n_nodes = n_nodes\n",
        "        self.n_output = n_output\n",
        "        self.n_sequences = n_sequences\n",
        "        self.lr = lr\n",
        "\n",
        "        #initializing weights and biases\n",
        "        self.Wx = np.random.randn(n_features, n_nodes)\n",
        "        self.Wh = np.random.randn(n_nodes, n_nodes)\n",
        "        self.B = np.zeros(n_nodes)\n",
        "        self.Wout = np.random.randn(n_nodes, n_output)\n",
        "        self.Bout = np.zeros(n_output)\n",
        "\n",
        "        #initializing forward propagation\n",
        "    def forward(self, X):\n",
        "        batch_size, n_sequences, n_features = X.shape\n",
        "        self.h = np.zeros((batch_size, self.n_nodes))\n",
        "        self.hs = np.zeros((batch_size, n_sequences, self.n_nodes))\n",
        "        self.ys = np.zeros((batch_size, n_sequences, self.n_output))\n",
        "\n",
        "        for t in range(n_sequences):\n",
        "            xt = X[:, t, :]\n",
        "            at = np.dot(xt, self.Wx) + np.dot(self.h, self.Wh) + self.B\n",
        "            self.h = np.tanh(at)\n",
        "            self.hs[:, t, :] = self.h\n",
        "            self.ys[:, t, :] = self.softmax(np.dot(self.h, self.Wout) + self.Bout)\n",
        "\n",
        "        return self.ys\n",
        "        #initializng activation function\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "    def fit(self, X, y, epochs=10):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(X)\n",
        "\n",
        "            pass\n",
        "\n",
        "    def predict(self, X):\n",
        "        output = self.forward(X)\n",
        "        return np.argmax(output[:, -1, :], axis=1)\n",
        "\n",
        "n_features = 4\n",
        "n_nodes = 5\n",
        "n_output = 3\n",
        "n_sequences = 10\n",
        "batch_size = 8\n",
        "\n",
        "X = np.random.randn(batch_size, n_sequences, n_features)\n",
        "y = np.random.randint(0, 3, (batch_size, n_sequences, n_output))\n",
        "\n",
        "model = ScratchSimpleRNNClassifier(n_features, n_nodes, n_output, n_sequences)\n",
        "output = model.forward(X)\n",
        "\n",
        "print(\"Output shape:\", output.shape)\n",
        "print(\"Output:\", output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Problem 2] Experiment of forward propagation with small sequence"
      ],
      "metadata": {
        "id": "OQrwDl95ukq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#assigning values to the weights and biases\n",
        "x = np.array([[[1, 2], [2, 3], [3, 4]]]) / 100\n",
        "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]]) / 100\n",
        "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]]) / 100\n",
        "b = np.array([1, 1, 1, 1])\n",
        "\n",
        "batch_size = x.shape[0]\n",
        "n_sequences = x.shape[1]\n",
        "n_features = x.shape[2]\n",
        "n_nodes = w_x.shape[1]\n",
        "\n",
        "h = np.zeros((batch_size, n_nodes))\n",
        "\n",
        "for t in range(n_sequences):\n",
        "    xt = x[:, t, :]\n",
        "    at = np.dot(xt, w_x) + np.dot(h, w_h) + b\n",
        "    h = np.tanh(at)\n",
        "\n",
        "print(\"Final hidden state h:\", h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKt4DC_Vui2F",
        "outputId": "8bdc4a05-e6ab-47cd-ebd9-c908ac76aa46"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final hidden state h: [[0.79494228 0.81839002 0.83939649 0.85584174]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Problem 3] (Advance assignment) Implementation of backpropagation"
      ],
      "metadata": {
        "id": "bwN0TzrvvJcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#implementation of simple RNN\n",
        "class ScratchSimpleRNNClassifier:\n",
        "    def __init__(self, n_features, n_nodes, n_outputs, lr=0.01):\n",
        "        self.n_features = n_features\n",
        "        self.n_nodes = n_nodes\n",
        "        self.n_outputs = n_outputs\n",
        "        self.lr = lr\n",
        "        # initialize weights and biases\n",
        "        self.W_x = np.random.randn(n_features, n_nodes)\n",
        "        self.W_h = np.random.randn(n_nodes, n_nodes)\n",
        "        self.b = np.zeros(n_nodes)\n",
        "        self.W_y = np.random.randn(n_nodes, n_outputs)\n",
        "        self.b_y = np.zeros(n_outputs)\n",
        "        # initialize forward propagation\n",
        "    def forward(self, x):\n",
        "        self.batch_size, self.n_sequences, self.n_features = x.shape\n",
        "        self.h = np.zeros((self.batch_size, self.n_sequences + 1, self.n_nodes))\n",
        "\n",
        "        for t in range(self.n_sequences):\n",
        "            self.h[:, t + 1, :] = np.tanh(np.dot(x[:, t, :], self.W_x) + np.dot(self.h[:, t, :], self.W_h) + self.b)\n",
        "\n",
        "        y = np.dot(self.h[:, -1, :], self.W_y) + self.b_y\n",
        "        return y\n",
        "        # initialize backward propagation\n",
        "    def backward(self, x, y_true, y_pred):\n",
        "        dW_x = np.zeros_like(self.W_x)\n",
        "        dW_h = np.zeros_like(self.W_h)\n",
        "        db = np.zeros_like(self.b)\n",
        "        dW_y = np.zeros_like(self.W_y)\n",
        "        db_y = np.zeros_like(self.b_y)\n",
        "\n",
        "        dy = y_pred - y_true\n",
        "\n",
        "        dW_y = np.dot(self.h[:, -1, :].T, dy) / self.batch_size\n",
        "        db_y = np.sum(dy, axis=0) / self.batch_size\n",
        "\n",
        "        dh = np.dot(dy, self.W_y.T)\n",
        "\n",
        "        for t in reversed(range(self.n_sequences)):\n",
        "            da = dh * (1 - self.h[:, t + 1, :] ** 2)\n",
        "            dW_x += np.dot(x[:, t, :].T, da) / self.batch_size\n",
        "            dW_h += np.dot(self.h[:, t, :].T, da) / self.batch_size\n",
        "            db += np.sum(da, axis=0) / self.batch_size\n",
        "\n",
        "            dh = np.dot(da, self.W_h.T)\n",
        "\n",
        "        self.W_x -= self.lr * dW_x\n",
        "        self.W_h -= self.lr * dW_h\n",
        "        self.b -= self.lr * db\n",
        "        self.W_y -= self.lr * dW_y\n",
        "        self.b_y -= self.lr * db_y\n",
        "\n",
        "    def fit(self, X, y, epochs=10):\n",
        "        for epoch in range(epochs):\n",
        "            y_pred = self.forward(X)\n",
        "            self.backward(X, y, y_pred)\n",
        "            loss = np.mean((y_pred - y) ** 2)\n",
        "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}')\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = self.forward(X)\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "x = np.array([[[1, 2], [2, 3], [3, 4]]]) / 100\n",
        "y_true = np.array([[0.5]])\n",
        "\n",
        "model = ScratchSimpleRNNClassifier(n_features=2, n_nodes=4, n_outputs=1, lr=0.01)\n",
        "model.fit(x, y_true, epochs=10)\n",
        "\n",
        "y_pred = model.predict(x)\n",
        "print(\"Predicted output:\", y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvCcZonGvGsU",
        "outputId": "83518aaf-b1c6-46cc-852e-409898ab2a95"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.1967\n",
            "Epoch 2/10, Loss: 0.0325\n",
            "Epoch 3/10, Loss: 0.0059\n",
            "Epoch 4/10, Loss: 0.0011\n",
            "Epoch 5/10, Loss: 0.0002\n",
            "Epoch 6/10, Loss: 0.0000\n",
            "Epoch 7/10, Loss: 0.0000\n",
            "Epoch 8/10, Loss: 0.0000\n",
            "Epoch 9/10, Loss: 0.0000\n",
            "Epoch 10/10, Loss: 0.0000\n",
            "Predicted output: [[0.4998773]]\n"
          ]
        }
      ]
    }
  ]
}