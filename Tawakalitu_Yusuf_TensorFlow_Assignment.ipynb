{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/0WYAmADWtb3EFAH0uP8u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tawaqalt/arbritrary/blob/master/Tawakalitu_Yusuf_TensorFlow_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Problem 1] Looking back on scratch"
      ],
      "metadata": {
        "id": "M-bU5QuK63nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. I had to initialize my init/created a class\n",
        "2. I need to initilaize weights\n",
        "3. I Implemented an epoch loop allows the model to iterate over the entire\n",
        "  dataset multiple times during training.\n",
        "4. I have to initilaze my forward and backward propagation\n",
        "5. I need to write codes for my activation function, initializer and optimizers\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kmBdQTvR7FET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "o6sU-4-JL1lm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the dataset"
      ],
      "metadata": {
        "id": "H3PyO_-v83cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the data\n",
        "data = pd.read_csv('Iris.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fQB3QraF-Avb",
        "outputId": "a30a851e-304f-45c8-fa66-744f286417ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1b5aaa4-eeb7-4d8e-bdc4-58e7af011d35\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1b5aaa4-eeb7-4d8e-bdc4-58e7af011d35')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1b5aaa4-eeb7-4d8e-bdc4-58e7af011d35 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1b5aaa4-eeb7-4d8e-bdc4-58e7af011d35');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6ae95752-c5ba-4467-be0f-376b2d1fda86\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ae95752-c5ba-4467-be0f-376b2d1fda86')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6ae95752-c5ba-4467-be0f-376b2d1fda86 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"Id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43,\n        \"min\": 1,\n        \"max\": 150,\n        \"num_unique_values\": 150,\n        \"samples\": [\n          74,\n          19,\n          119\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SepalLengthCm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.828066127977863,\n        \"min\": 4.3,\n        \"max\": 7.9,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          6.2,\n          4.5,\n          5.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SepalWidthCm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4335943113621737,\n        \"min\": 2.0,\n        \"max\": 4.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          2.3,\n          4.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PetalLengthCm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7644204199522626,\n        \"min\": 1.0,\n        \"max\": 6.9,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          6.7,\n          3.8,\n          3.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PetalWidthCm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7631607417008411,\n        \"min\": 0.1,\n        \"max\": 2.5,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.2,\n          1.2,\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Species\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Iris-setosa\",\n          \"Iris-versicolor\",\n          \"Iris-virginica\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpF7tGa3-hyH",
        "outputId": "38b5528d-7b82-4de7-8042-121b698b7a84"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LizePB17-hjm",
        "outputId": "72f9cf56-b192-4bc6-ded0-953f4c786e5a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 6 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             150 non-null    int64  \n",
            " 1   SepalLengthCm  150 non-null    float64\n",
            " 2   SepalWidthCm   150 non-null    float64\n",
            " 3   PetalLengthCm  150 non-null    float64\n",
            " 4   PetalWidthCm   150 non-null    float64\n",
            " 5   Species        150 non-null    object \n",
            "dtypes: float64(4), int64(1), object(1)\n",
            "memory usage: 7.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IuHckHg-mA7",
        "outputId": "25e03848-b348-4784-8f30-8c4807ee48c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id               0\n",
              "SepalLengthCm    0\n",
              "SepalWidthCm     0\n",
              "PetalLengthCm    0\n",
              "PetalWidthCm     0\n",
              "Species          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Problem 2] Consider the correspondence between scratch and TensorFlow"
      ],
      "metadata": {
        "id": "zeXKbfYT8nWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Iris.csv\")\n",
        "\n",
        "# Condition extraction from data frame\n",
        "df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "\n",
        "# Convert to NumPy array\n",
        "X = np.array(X, dtype=np.float32)\n",
        "y = np.array(y)\n",
        "# Convert labels to numbers\n",
        "y = np.where(y == \"Iris-versicolor\", 0, 1)\n",
        "y = y.astype(np.float32)[:, np.newaxis]\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# Further split into train and val\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "class GetMiniBatch:\n",
        "    def __init__(self, X, y, batch_size=10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        p0 = item * self.batch_size\n",
        "        p1 = item * self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter * self.batch_size\n",
        "        p1 = self._counter * self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "\n",
        "# Hyperparameter settings\n",
        "learning_rate = 0.001\n",
        "batch_size = 10\n",
        "num_epochs = 100\n",
        "\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 1\n",
        "\n",
        "# Train mini batch iterator\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# Define the model using Keras\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(n_hidden1, activation='relu', input_shape=(n_input,)),\n",
        "    tf.keras.layers.Dense(n_hidden2, activation='relu'),\n",
        "    tf.keras.layers.Dense(n_classes, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    total_batch = 0\n",
        "    for mini_batch_x, mini_batch_y in get_mini_batch_train:\n",
        "        loss, acc = model.train_on_batch(mini_batch_x, mini_batch_y)\n",
        "        total_loss += loss\n",
        "        total_acc += acc\n",
        "        total_batch += 1\n",
        "\n",
        "    total_loss /= total_batch\n",
        "    total_acc /= total_batch\n",
        "\n",
        "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f\"Epoch {epoch}, loss: {total_loss:.4f}, val_loss: {val_loss:.4f}, acc: {total_acc:.3f}, val_acc: {val_acc:.3f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"test_acc: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl1T4QCcVC4w",
        "outputId": "497927e0-f83d-4b0b-ccd7-9b37aae243bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss: 0.7935, val_loss: 0.6748, acc: 0.557, val_acc: 0.375\n",
            "Epoch 1, loss: 0.6701, val_loss: 0.7807, acc: 0.550, val_acc: 0.375\n",
            "Epoch 2, loss: 0.6681, val_loss: 0.7428, acc: 0.550, val_acc: 0.375\n",
            "Epoch 3, loss: 0.6412, val_loss: 0.6786, acc: 0.550, val_acc: 0.375\n",
            "Epoch 4, loss: 0.6329, val_loss: 0.6559, acc: 0.550, val_acc: 0.438\n",
            "Epoch 5, loss: 0.6290, val_loss: 0.6590, acc: 0.579, val_acc: 0.375\n",
            "Epoch 6, loss: 0.6214, val_loss: 0.6672, acc: 0.564, val_acc: 0.375\n",
            "Epoch 7, loss: 0.6141, val_loss: 0.6630, acc: 0.550, val_acc: 0.375\n",
            "Epoch 8, loss: 0.6058, val_loss: 0.6492, acc: 0.550, val_acc: 0.375\n",
            "Epoch 9, loss: 0.5973, val_loss: 0.6351, acc: 0.579, val_acc: 0.500\n",
            "Epoch 10, loss: 0.5857, val_loss: 0.6197, acc: 0.664, val_acc: 0.562\n",
            "Epoch 11, loss: 0.5721, val_loss: 0.6070, acc: 0.729, val_acc: 0.688\n",
            "Epoch 12, loss: 0.5602, val_loss: 0.5965, acc: 0.757, val_acc: 0.750\n",
            "Epoch 13, loss: 0.5486, val_loss: 0.5852, acc: 0.771, val_acc: 0.750\n",
            "Epoch 14, loss: 0.5370, val_loss: 0.5727, acc: 0.800, val_acc: 0.812\n",
            "Epoch 15, loss: 0.5257, val_loss: 0.5603, acc: 0.829, val_acc: 0.812\n",
            "Epoch 16, loss: 0.5144, val_loss: 0.5487, acc: 0.871, val_acc: 0.812\n",
            "Epoch 17, loss: 0.5032, val_loss: 0.5371, acc: 0.900, val_acc: 0.875\n",
            "Epoch 18, loss: 0.4918, val_loss: 0.5251, acc: 0.900, val_acc: 0.875\n",
            "Epoch 19, loss: 0.4806, val_loss: 0.5131, acc: 0.900, val_acc: 0.875\n",
            "Epoch 20, loss: 0.4693, val_loss: 0.5012, acc: 0.900, val_acc: 0.938\n",
            "Epoch 21, loss: 0.4580, val_loss: 0.4892, acc: 0.900, val_acc: 0.938\n",
            "Epoch 22, loss: 0.4466, val_loss: 0.4771, acc: 0.914, val_acc: 0.938\n",
            "Epoch 23, loss: 0.4353, val_loss: 0.4649, acc: 0.914, val_acc: 0.938\n",
            "Epoch 24, loss: 0.4241, val_loss: 0.4529, acc: 0.914, val_acc: 0.938\n",
            "Epoch 25, loss: 0.4129, val_loss: 0.4410, acc: 0.929, val_acc: 1.000\n",
            "Epoch 26, loss: 0.4017, val_loss: 0.4290, acc: 0.943, val_acc: 1.000\n",
            "Epoch 27, loss: 0.3907, val_loss: 0.4172, acc: 0.943, val_acc: 1.000\n",
            "Epoch 28, loss: 0.3799, val_loss: 0.4055, acc: 0.943, val_acc: 1.000\n",
            "Epoch 29, loss: 0.3691, val_loss: 0.3940, acc: 0.943, val_acc: 1.000\n",
            "Epoch 30, loss: 0.3586, val_loss: 0.3829, acc: 0.943, val_acc: 1.000\n",
            "Epoch 31, loss: 0.3483, val_loss: 0.3716, acc: 0.957, val_acc: 1.000\n",
            "Epoch 32, loss: 0.3381, val_loss: 0.3608, acc: 0.957, val_acc: 1.000\n",
            "Epoch 33, loss: 0.3283, val_loss: 0.3504, acc: 0.957, val_acc: 1.000\n",
            "Epoch 34, loss: 0.3186, val_loss: 0.3398, acc: 0.957, val_acc: 1.000\n",
            "Epoch 35, loss: 0.3092, val_loss: 0.3298, acc: 0.957, val_acc: 1.000\n",
            "Epoch 36, loss: 0.3002, val_loss: 0.3201, acc: 0.957, val_acc: 1.000\n",
            "Epoch 37, loss: 0.2913, val_loss: 0.3106, acc: 0.957, val_acc: 1.000\n",
            "Epoch 38, loss: 0.2828, val_loss: 0.3013, acc: 0.957, val_acc: 1.000\n",
            "Epoch 39, loss: 0.2746, val_loss: 0.2925, acc: 0.971, val_acc: 1.000\n",
            "Epoch 40, loss: 0.2666, val_loss: 0.2839, acc: 0.971, val_acc: 1.000\n",
            "Epoch 41, loss: 0.2589, val_loss: 0.2756, acc: 0.971, val_acc: 1.000\n",
            "Epoch 42, loss: 0.2516, val_loss: 0.2677, acc: 0.971, val_acc: 1.000\n",
            "Epoch 43, loss: 0.2445, val_loss: 0.2600, acc: 0.971, val_acc: 1.000\n",
            "Epoch 44, loss: 0.2376, val_loss: 0.2525, acc: 0.971, val_acc: 1.000\n",
            "Epoch 45, loss: 0.2311, val_loss: 0.2455, acc: 0.971, val_acc: 1.000\n",
            "Epoch 46, loss: 0.2249, val_loss: 0.2388, acc: 0.971, val_acc: 1.000\n",
            "Epoch 47, loss: 0.2188, val_loss: 0.2321, acc: 0.971, val_acc: 1.000\n",
            "Epoch 48, loss: 0.2131, val_loss: 0.2259, acc: 0.971, val_acc: 1.000\n",
            "Epoch 49, loss: 0.2076, val_loss: 0.2199, acc: 0.971, val_acc: 1.000\n",
            "Epoch 50, loss: 0.2023, val_loss: 0.2141, acc: 0.971, val_acc: 1.000\n",
            "Epoch 51, loss: 0.1973, val_loss: 0.2086, acc: 0.971, val_acc: 1.000\n",
            "Epoch 52, loss: 0.1925, val_loss: 0.2033, acc: 0.971, val_acc: 1.000\n",
            "Epoch 53, loss: 0.1879, val_loss: 0.1982, acc: 0.971, val_acc: 1.000\n",
            "Epoch 54, loss: 0.1834, val_loss: 0.1933, acc: 0.971, val_acc: 1.000\n",
            "Epoch 55, loss: 0.1792, val_loss: 0.1886, acc: 0.971, val_acc: 1.000\n",
            "Epoch 56, loss: 0.1750, val_loss: 0.1838, acc: 0.971, val_acc: 1.000\n",
            "Epoch 57, loss: 0.1710, val_loss: 0.1794, acc: 0.971, val_acc: 1.000\n",
            "Epoch 58, loss: 0.1672, val_loss: 0.1753, acc: 0.971, val_acc: 1.000\n",
            "Epoch 59, loss: 0.1635, val_loss: 0.1712, acc: 0.971, val_acc: 1.000\n",
            "Epoch 60, loss: 0.1600, val_loss: 0.1672, acc: 0.971, val_acc: 1.000\n",
            "Epoch 61, loss: 0.1566, val_loss: 0.1635, acc: 0.971, val_acc: 1.000\n",
            "Epoch 62, loss: 0.1534, val_loss: 0.1599, acc: 0.971, val_acc: 1.000\n",
            "Epoch 63, loss: 0.1504, val_loss: 0.1565, acc: 0.971, val_acc: 1.000\n",
            "Epoch 64, loss: 0.1474, val_loss: 0.1531, acc: 0.971, val_acc: 1.000\n",
            "Epoch 65, loss: 0.1446, val_loss: 0.1499, acc: 0.971, val_acc: 1.000\n",
            "Epoch 66, loss: 0.1419, val_loss: 0.1469, acc: 0.971, val_acc: 1.000\n",
            "Epoch 67, loss: 0.1393, val_loss: 0.1439, acc: 0.971, val_acc: 1.000\n",
            "Epoch 68, loss: 0.1368, val_loss: 0.1411, acc: 0.971, val_acc: 1.000\n",
            "Epoch 69, loss: 0.1344, val_loss: 0.1383, acc: 0.971, val_acc: 1.000\n",
            "Epoch 70, loss: 0.1321, val_loss: 0.1357, acc: 0.971, val_acc: 1.000\n",
            "Epoch 71, loss: 0.1298, val_loss: 0.1331, acc: 0.971, val_acc: 1.000\n",
            "Epoch 72, loss: 0.1278, val_loss: 0.1307, acc: 0.971, val_acc: 1.000\n",
            "Epoch 73, loss: 0.1257, val_loss: 0.1283, acc: 0.971, val_acc: 1.000\n",
            "Epoch 74, loss: 0.1237, val_loss: 0.1261, acc: 0.971, val_acc: 1.000\n",
            "Epoch 75, loss: 0.1219, val_loss: 0.1239, acc: 0.971, val_acc: 1.000\n",
            "Epoch 76, loss: 0.1200, val_loss: 0.1217, acc: 0.971, val_acc: 1.000\n",
            "Epoch 77, loss: 0.1182, val_loss: 0.1197, acc: 0.971, val_acc: 1.000\n",
            "Epoch 78, loss: 0.1166, val_loss: 0.1177, acc: 0.971, val_acc: 1.000\n",
            "Epoch 79, loss: 0.1149, val_loss: 0.1158, acc: 0.971, val_acc: 1.000\n",
            "Epoch 80, loss: 0.1133, val_loss: 0.1139, acc: 0.971, val_acc: 1.000\n",
            "Epoch 81, loss: 0.1118, val_loss: 0.1121, acc: 0.971, val_acc: 1.000\n",
            "Epoch 82, loss: 0.1103, val_loss: 0.1104, acc: 0.971, val_acc: 1.000\n",
            "Epoch 83, loss: 0.1089, val_loss: 0.1087, acc: 0.971, val_acc: 1.000\n",
            "Epoch 84, loss: 0.1075, val_loss: 0.1070, acc: 0.971, val_acc: 1.000\n",
            "Epoch 85, loss: 0.1061, val_loss: 0.1055, acc: 0.971, val_acc: 1.000\n",
            "Epoch 86, loss: 0.1049, val_loss: 0.1039, acc: 0.971, val_acc: 1.000\n",
            "Epoch 87, loss: 0.1036, val_loss: 0.1024, acc: 0.971, val_acc: 1.000\n",
            "Epoch 88, loss: 0.1024, val_loss: 0.1010, acc: 0.971, val_acc: 1.000\n",
            "Epoch 89, loss: 0.1012, val_loss: 0.0996, acc: 0.971, val_acc: 1.000\n",
            "Epoch 90, loss: 0.1001, val_loss: 0.0982, acc: 0.971, val_acc: 1.000\n",
            "Epoch 91, loss: 0.0989, val_loss: 0.0969, acc: 0.971, val_acc: 1.000\n",
            "Epoch 92, loss: 0.0978, val_loss: 0.0956, acc: 0.971, val_acc: 1.000\n",
            "Epoch 93, loss: 0.0968, val_loss: 0.0943, acc: 0.971, val_acc: 1.000\n",
            "Epoch 94, loss: 0.0958, val_loss: 0.0931, acc: 0.971, val_acc: 1.000\n",
            "Epoch 95, loss: 0.0948, val_loss: 0.0919, acc: 0.971, val_acc: 1.000\n",
            "Epoch 96, loss: 0.0938, val_loss: 0.0907, acc: 0.971, val_acc: 1.000\n",
            "Epoch 97, loss: 0.0929, val_loss: 0.0896, acc: 0.971, val_acc: 1.000\n",
            "Epoch 98, loss: 0.0920, val_loss: 0.0885, acc: 0.971, val_acc: 1.000\n",
            "Epoch 99, loss: 0.0911, val_loss: 0.0874, acc: 0.971, val_acc: 1.000\n",
            "test_acc: 0.900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries\n",
        "# New Section"
      ],
      "metadata": {
        "id": "Z5SNUtnSNxlU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Preprocess the Data"
      ],
      "metadata": {
        "id": "pXxPx58nN2mC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target variable\n",
        "X = data.drop('Species', axis=1)\n",
        "y = data['Species']\n",
        "\n",
        "# One-hot encode the target variable\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_encoded = encoder.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the feature values\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "tI4dtxA2L7Vq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the TensorFlow Model"
      ],
      "metadata": {
        "id": "2lb2Pn-ON486"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  # 3 output classes for the species\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',  # Use categorical crossentropy for multi-class\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "K-taKpTSNZRc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ],
      "metadata": {
        "id": "u1EFpqY7N9BY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=5, validation_split=0.2)"
      ],
      "metadata": {
        "id": "BuBkaImANeX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d590358-190a-42b1-852d-96ac50c5962e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 14ms/step - loss: 1.2809 - accuracy: 0.2500 - val_loss: 1.1260 - val_accuracy: 0.2083\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1.1916 - accuracy: 0.2292 - val_loss: 1.0410 - val_accuracy: 0.4167\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.1166 - accuracy: 0.3125 - val_loss: 0.9781 - val_accuracy: 0.5833\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.0576 - accuracy: 0.3125 - val_loss: 0.9186 - val_accuracy: 0.5417\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.0045 - accuracy: 0.3229 - val_loss: 0.8667 - val_accuracy: 0.4583\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.9613 - accuracy: 0.3333 - val_loss: 0.8192 - val_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.9227 - accuracy: 0.3125 - val_loss: 0.7719 - val_accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.8910 - accuracy: 0.3229 - val_loss: 0.7324 - val_accuracy: 0.5833\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8589 - accuracy: 0.3229 - val_loss: 0.7027 - val_accuracy: 0.5833\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.8126 - accuracy: 0.4062 - val_loss: 0.6576 - val_accuracy: 0.6667\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7432 - accuracy: 0.7396 - val_loss: 0.6198 - val_accuracy: 0.7917\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.8021 - val_loss: 0.5802 - val_accuracy: 0.7917\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6098 - accuracy: 0.8438 - val_loss: 0.5423 - val_accuracy: 0.7917\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5461 - accuracy: 0.8646 - val_loss: 0.5051 - val_accuracy: 0.8333\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.8750 - val_loss: 0.4672 - val_accuracy: 0.8333\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8854 - val_loss: 0.4309 - val_accuracy: 0.8333\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8958 - val_loss: 0.4077 - val_accuracy: 0.8750\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8750 - val_loss: 0.3924 - val_accuracy: 0.9583\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.9062 - val_loss: 0.3634 - val_accuracy: 0.9583\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3071 - accuracy: 0.9167 - val_loss: 0.3443 - val_accuracy: 0.9583\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2865 - accuracy: 0.9167 - val_loss: 0.3274 - val_accuracy: 0.9583\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2685 - accuracy: 0.9271 - val_loss: 0.3128 - val_accuracy: 0.9583\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.9375 - val_loss: 0.3014 - val_accuracy: 0.9583\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2402 - accuracy: 0.9375 - val_loss: 0.2898 - val_accuracy: 0.9583\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2290 - accuracy: 0.9479 - val_loss: 0.2812 - val_accuracy: 0.9583\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2182 - accuracy: 0.9375 - val_loss: 0.2774 - val_accuracy: 0.9583\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2086 - accuracy: 0.9375 - val_loss: 0.2682 - val_accuracy: 0.9583\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1992 - accuracy: 0.9375 - val_loss: 0.2641 - val_accuracy: 0.9583\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1907 - accuracy: 0.9583 - val_loss: 0.2485 - val_accuracy: 0.9583\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1820 - accuracy: 0.9583 - val_loss: 0.2406 - val_accuracy: 0.9583\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9583 - val_loss: 0.2342 - val_accuracy: 0.9583\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1667 - accuracy: 0.9583 - val_loss: 0.2273 - val_accuracy: 0.9583\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1597 - accuracy: 0.9688 - val_loss: 0.2241 - val_accuracy: 0.9583\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1531 - accuracy: 0.9688 - val_loss: 0.2188 - val_accuracy: 0.9583\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1459 - accuracy: 0.9688 - val_loss: 0.2118 - val_accuracy: 0.9583\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1399 - accuracy: 0.9688 - val_loss: 0.2055 - val_accuracy: 0.9583\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1345 - accuracy: 0.9792 - val_loss: 0.2031 - val_accuracy: 0.9583\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1288 - accuracy: 0.9792 - val_loss: 0.1958 - val_accuracy: 0.9583\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.9792 - val_loss: 0.1942 - val_accuracy: 0.9583\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9896 - val_loss: 0.1944 - val_accuracy: 0.9583\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1129 - accuracy: 0.9896 - val_loss: 0.1884 - val_accuracy: 0.9583\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9896 - val_loss: 0.1829 - val_accuracy: 0.9583\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9583\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9583\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9583\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0915 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9583\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9583\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9583\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9583\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9583\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9583\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9583\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9583\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9583\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9583\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9583\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9583\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9583\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9583\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9583\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9583\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9583\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9583\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9583\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9583\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9583\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9583\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9583\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9583\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9583\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9583\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.1454 - val_accuracy: 0.9583\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9583\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9583\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9583\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9583\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9583\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9583\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9583\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9583\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9583\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9583\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9583\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9583\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9583\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9583\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9583\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9583\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9583\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9583\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9583\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9583\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9583\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9583\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9583\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9583\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9583\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9583\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.9583\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9583\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x786a37775f00>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the Model"
      ],
      "metadata": {
        "id": "GqlAlzVYOFtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "QgeCcx3BNrPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9852b1-ebaa-4829-eae9-7a86e8cb13b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Test Loss: 0.0081, Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of Changes for Multi-Class Classification\n",
        "\n",
        "In the provided TensorFlow code, the key changes made to adapt the model for multi-class classification are:\n",
        "\n",
        "Loss Function: Instead of using sigmoid_cross_entropy_with_logits, we use categorical_crossentropy, which is suitable for multi-class problems.\n",
        "Output Layer Activation: The output layer uses the softmax activation function, which is appropriate for multi-class classification as it outputs probabilities for each class.\n",
        "\n",
        "Correct Prediction Calculation: The method for calculating correct predictions is simplified, as TensorFlow handles this internally when using categorical_crossentropy."
      ],
      "metadata": {
        "id": "MaoZP5iLRWYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 4] Create a model of House Price"
      ],
      "metadata": {
        "id": "Z_h0r8gqPIaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "HJuk-TKwPLnQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f7decacc-36f4-4e54-a68c-8a6af8f4fea1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-078b9897-687c-46dd-ac1d-53271d69a59e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  81 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-078b9897-687c-46dd-ac1d-53271d69a59e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-078b9897-687c-46dd-ac1d-53271d69a59e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-078b9897-687c-46dd-ac1d-53271d69a59e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ebef5b50-7008-4e9d-a8f0-298352f528fd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ebef5b50-7008-4e9d-a8f0-298352f528fd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ebef5b50-7008-4e9d-a8f0-298352f528fd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Condition extraction from data frame\n",
        "X1 = df[['GrLivArea', 'YearBuilt']]\n",
        "y1 = df['SalePrice']\n",
        "\n",
        "\n",
        "# Convert to NumPy array\n",
        "X1 = np.array(X, dtype=np.float32)\n",
        "y1 = np.array(y)\n",
        "# Convert labels to numbers\n",
        "y1 = np.where(y == \"Iris-versicolor\", 0, 1)\n",
        "y1 = y1.astype(np.float32)[:, np.newaxis]\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=0)\n",
        "# Further split into train and val\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "class GetMiniBatch:\n",
        "    def __init__(self, X, y, batch_size=10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        p0 = item * self.batch_size\n",
        "        p1 = item * self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter * self.batch_size\n",
        "        p1 = self._counter * self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "\n",
        "# Hyperparameter settings\n",
        "learning_rate = 0.001\n",
        "batch_size = 10\n",
        "num_epochs = 100\n",
        "\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 1\n",
        "\n",
        "# Train mini batch iterator\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# Define the model using Keras\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(n_hidden1, activation='relu', input_shape=(n_input,)),\n",
        "    tf.keras.layers.Dense(n_hidden2, activation='relu'),\n",
        "    tf.keras.layers.Dense(n_classes, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    total_batch = 0\n",
        "    for mini_batch_x, mini_batch_y in get_mini_batch_train:\n",
        "        loss, acc = model.train_on_batch(mini_batch_x, mini_batch_y)\n",
        "        total_loss += loss\n",
        "        total_acc += acc\n",
        "        total_batch += 1\n",
        "\n",
        "    total_loss /= total_batch\n",
        "    total_acc /= total_batch\n",
        "\n",
        "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f\"Epoch {epoch}, loss: {total_loss:.4f}, val_loss: {val_loss:.4f}, acc: {total_acc:.3f}, val_acc: {val_acc:.3f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"test_acc: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS5lPId5gIx5",
        "outputId": "2fa71053-ee64-4ea7-e1eb-4c03ddbb6f78"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 1, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 2, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 3, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 4, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 5, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 6, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 7, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 8, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 9, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 10, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 11, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 12, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 13, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 14, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 15, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 16, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 17, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 18, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 19, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 20, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 21, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 22, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 23, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 24, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 25, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 26, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 27, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 28, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 29, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 30, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 31, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 32, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 33, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 34, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 35, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 36, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 37, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 38, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 39, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 40, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 41, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 42, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 43, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 44, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 45, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 46, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 47, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 48, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 49, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 50, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 51, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 52, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 53, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 54, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 55, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 56, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 57, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 58, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 59, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 60, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 61, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 62, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 63, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 64, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 65, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 66, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 67, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 68, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 69, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 70, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 71, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 72, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 73, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 74, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 75, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 76, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 77, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 78, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 79, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 80, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 81, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 82, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 83, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 84, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 85, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 86, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 87, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 88, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 89, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 90, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 91, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 92, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 93, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 94, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 95, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 96, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 97, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 98, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "Epoch 99, loss: 0.0000, val_loss: 0.0000, acc: 1.000, val_acc: 1.000\n",
            "test_acc: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the relevant features\n",
        "X = df[['GrLivArea', 'YearBuilt']]\n",
        "y = df['SalePrice']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the feature values\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "hS-ECwopPmlJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Input shape matches features\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mse',\n",
        "              metrics=['mae'])\n"
      ],
      "metadata": {
        "id": "h80PcqSEQy8p"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "HDHkeWzHQ2yQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba330fa3-cce9-4cb2-9a95-64a9d2869633"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 1s 8ms/step - loss: 39146835968.0000 - mae: 181526.1094 - val_loss: 37841829888.0000 - val_mae: 181101.2344\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 39146315776.0000 - mae: 181524.6875 - val_loss: 37841121280.0000 - val_mae: 181099.2969\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 39145271296.0000 - mae: 181521.8906 - val_loss: 37839654912.0000 - val_mae: 181095.3125\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 39143194624.0000 - mae: 181516.3125 - val_loss: 37836881920.0000 - val_mae: 181087.9375\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 39139516416.0000 - mae: 181506.5156 - val_loss: 37832220672.0000 - val_mae: 181075.6250\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 39133597696.0000 - mae: 181491.0625 - val_loss: 37825077248.0000 - val_mae: 181057.0469\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 39124938752.0000 - mae: 181468.7500 - val_loss: 37814976512.0000 - val_mae: 181030.9375\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 39112728576.0000 - mae: 181437.6094 - val_loss: 37801025536.0000 - val_mae: 180995.4062\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 39096340480.0000 - mae: 181396.0469 - val_loss: 37782585344.0000 - val_mae: 180948.7500\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 39074775040.0000 - mae: 181342.9062 - val_loss: 37759188992.0000 - val_mae: 180890.0781\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 39047606272.0000 - mae: 181275.9375 - val_loss: 37729771520.0000 - val_mae: 180816.8750\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 39014354944.0000 - mae: 181194.7656 - val_loss: 37694771200.0000 - val_mae: 180729.9219\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 38974402560.0000 - mae: 181097.2969 - val_loss: 37652226048.0000 - val_mae: 180625.2656\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 38927273984.0000 - mae: 180981.2969 - val_loss: 37601841152.0000 - val_mae: 180502.1406\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 38871126016.0000 - mae: 180846.8594 - val_loss: 37543768064.0000 - val_mae: 180359.8594\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 38805872640.0000 - mae: 180690.1875 - val_loss: 37475512320.0000 - val_mae: 180193.7812\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 38731784192.0000 - mae: 180511.4688 - val_loss: 37398089728.0000 - val_mae: 180005.8750\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 38646644736.0000 - mae: 180307.7656 - val_loss: 37312061440.0000 - val_mae: 179795.9688\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 38552051712.0000 - mae: 180082.7344 - val_loss: 37215301632.0000 - val_mae: 179561.1562\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 38446792704.0000 - mae: 179828.0781 - val_loss: 37105135616.0000 - val_mae: 179294.7188\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 38327455744.0000 - mae: 179543.0781 - val_loss: 36985405440.0000 - val_mae: 179004.7812\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 38197903360.0000 - mae: 179234.8750 - val_loss: 36854575104.0000 - val_mae: 178688.1875\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 38057119744.0000 - mae: 178898.7031 - val_loss: 36710461440.0000 - val_mae: 178340.0469\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 37902204928.0000 - mae: 178530.0781 - val_loss: 36554657792.0000 - val_mae: 177964.0469\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 37735288832.0000 - mae: 178129.0469 - val_loss: 36385857536.0000 - val_mae: 177555.5312\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 37554147328.0000 - mae: 177699.0781 - val_loss: 36203503616.0000 - val_mae: 177114.4062\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 37359538176.0000 - mae: 177237.1250 - val_loss: 36011884544.0000 - val_mae: 176648.5938\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 37154074624.0000 - mae: 176745.1875 - val_loss: 35806253056.0000 - val_mae: 176148.1562\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 36937080832.0000 - mae: 176226.0625 - val_loss: 35593535488.0000 - val_mae: 175626.5625\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 36709990400.0000 - mae: 175675.1875 - val_loss: 35364147200.0000 - val_mae: 175064.7656\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 36465729536.0000 - mae: 175086.4375 - val_loss: 35116355584.0000 - val_mae: 174459.5625\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 36207153152.0000 - mae: 174462.2031 - val_loss: 34864619520.0000 - val_mae: 173838.3750\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 35938762752.0000 - mae: 173809.2812 - val_loss: 34597814272.0000 - val_mae: 173177.4688\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 35653877760.0000 - mae: 173113.0469 - val_loss: 34311813120.0000 - val_mae: 172470.4062\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 35355258880.0000 - mae: 172379.4219 - val_loss: 34016610304.0000 - val_mae: 171736.2812\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 35040591872.0000 - mae: 171614.2812 - val_loss: 33710893056.0000 - val_mae: 170970.9531\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 34719916032.0000 - mae: 170820.2500 - val_loss: 33388613632.0000 - val_mae: 170163.3438\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 34383806464.0000 - mae: 169988.1875 - val_loss: 33057646592.0000 - val_mae: 169329.2188\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 34032564224.0000 - mae: 169116.0156 - val_loss: 32711659520.0000 - val_mae: 168452.8281\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 33665449984.0000 - mae: 168201.1875 - val_loss: 32353144832.0000 - val_mae: 167539.6250\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 33289658368.0000 - mae: 167257.8281 - val_loss: 31976810496.0000 - val_mae: 166581.0156\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 32897863680.0000 - mae: 166264.8750 - val_loss: 31586420736.0000 - val_mae: 165578.7031\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 32492822528.0000 - mae: 165242.8281 - val_loss: 31201978368.0000 - val_mae: 164578.7031\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 32084811776.0000 - mae: 164188.6250 - val_loss: 30792005632.0000 - val_mae: 163511.3906\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 31654991872.0000 - mae: 163085.8438 - val_loss: 30366830592.0000 - val_mae: 162398.1094\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 31216035840.0000 - mae: 161937.3125 - val_loss: 29937620992.0000 - val_mae: 161264.4844\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 30768953344.0000 - mae: 160777.3906 - val_loss: 29506105344.0000 - val_mae: 160111.5156\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 30318694400.0000 - mae: 159581.3906 - val_loss: 29056866304.0000 - val_mae: 158903.0781\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 29850191872.0000 - mae: 158331.7656 - val_loss: 28594991104.0000 - val_mae: 157655.9531\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 29368733696.0000 - mae: 157056.6719 - val_loss: 28133826560.0000 - val_mae: 156395.5781\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 28884393984.0000 - mae: 155723.5156 - val_loss: 27648376832.0000 - val_mae: 155062.4375\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 28394967040.0000 - mae: 154378.9219 - val_loss: 27157729280.0000 - val_mae: 153701.4531\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 27883343872.0000 - mae: 152986.0000 - val_loss: 26671489024.0000 - val_mae: 152331.2344\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 27382407168.0000 - mae: 151579.1562 - val_loss: 26178680832.0000 - val_mae: 150933.7500\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 26864392192.0000 - mae: 150142.5625 - val_loss: 25672617984.0000 - val_mae: 149482.8438\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 26345283584.0000 - mae: 148674.8594 - val_loss: 25156079616.0000 - val_mae: 147989.7031\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 25814384640.0000 - mae: 147177.7500 - val_loss: 24648519680.0000 - val_mae: 146496.6875\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 25283764224.0000 - mae: 145620.7031 - val_loss: 24114708480.0000 - val_mae: 144918.1094\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 24733321216.0000 - mae: 144035.5312 - val_loss: 23575822336.0000 - val_mae: 143306.1719\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 24186589184.0000 - mae: 142409.1250 - val_loss: 23048865792.0000 - val_mae: 141700.5156\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 23646609408.0000 - mae: 140788.4062 - val_loss: 22514665472.0000 - val_mae: 140057.7188\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 23093565440.0000 - mae: 139124.6250 - val_loss: 21976412160.0000 - val_mae: 138377.4375\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 22544515072.0000 - mae: 137447.5625 - val_loss: 21440716800.0000 - val_mae: 136686.6250\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 21996652544.0000 - mae: 135747.1406 - val_loss: 20910469120.0000 - val_mae: 134978.6250\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 21450903552.0000 - mae: 134029.3281 - val_loss: 20375478272.0000 - val_mae: 133231.8281\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 20910741504.0000 - mae: 132291.7812 - val_loss: 19841241088.0000 - val_mae: 131464.8281\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 20362280960.0000 - mae: 130497.7656 - val_loss: 19293339648.0000 - val_mae: 129623.4922\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 19815313408.0000 - mae: 128704.3594 - val_loss: 18780776448.0000 - val_mae: 127860.0312\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 19287572480.0000 - mae: 126902.6172 - val_loss: 18248970240.0000 - val_mae: 126017.1719\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 18755639296.0000 - mae: 125069.9766 - val_loss: 17713192960.0000 - val_mae: 124123.2812\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 18216912896.0000 - mae: 123200.3750 - val_loss: 17197875200.0000 - val_mae: 122265.7266\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 17694556160.0000 - mae: 121347.5859 - val_loss: 16692459520.0000 - val_mae: 120407.4297\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 17177271296.0000 - mae: 119453.7031 - val_loss: 16168081408.0000 - val_mae: 118457.1094\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 16652357632.0000 - mae: 117488.8594 - val_loss: 15649599488.0000 - val_mae: 116484.5234\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 16136219648.0000 - mae: 115560.7969 - val_loss: 15152865280.0000 - val_mae: 114548.0781\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 15619208192.0000 - mae: 113587.4609 - val_loss: 14650779648.0000 - val_mae: 112553.6094\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 15131722752.0000 - mae: 111634.5781 - val_loss: 14160866304.0000 - val_mae: 110563.6562\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 14637947904.0000 - mae: 109648.8516 - val_loss: 13675673600.0000 - val_mae: 108558.5469\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 14161868800.0000 - mae: 107676.4453 - val_loss: 13214570496.0000 - val_mae: 106602.0391\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 13696590848.0000 - mae: 105734.6797 - val_loss: 12749529088.0000 - val_mae: 104588.3906\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 13238520832.0000 - mae: 103731.1953 - val_loss: 12296045568.0000 - val_mae: 102577.8359\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 12795350016.0000 - mae: 101772.2656 - val_loss: 11852557312.0000 - val_mae: 100567.1953\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 12357172224.0000 - mae: 99776.0156 - val_loss: 11420706816.0000 - val_mae: 98557.6641\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 11929857024.0000 - mae: 97787.0625 - val_loss: 11009860608.0000 - val_mae: 96590.0938\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 11521959936.0000 - mae: 95843.1719 - val_loss: 10590525440.0000 - val_mae: 94541.3125\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 11109627904.0000 - mae: 93851.2734 - val_loss: 10193837056.0000 - val_mae: 92546.5156\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 10717519872.0000 - mae: 91903.2500 - val_loss: 9799741440.0000 - val_mae: 90530.6875\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 10339595264.0000 - mae: 89966.5547 - val_loss: 9414286336.0000 - val_mae: 88537.2734\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 9966823424.0000 - mae: 87987.1328 - val_loss: 9047888896.0000 - val_mae: 86584.6172\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 9610260480.0000 - mae: 86087.3750 - val_loss: 8695426048.0000 - val_mae: 84650.5625\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 9265291264.0000 - mae: 84161.5000 - val_loss: 8349627904.0000 - val_mae: 82706.5078\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 8931746816.0000 - mae: 82222.4141 - val_loss: 8005169152.0000 - val_mae: 80725.7188\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 8602388480.0000 - mae: 80331.6250 - val_loss: 7688294400.0000 - val_mae: 78840.7656\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 8293258240.0000 - mae: 78426.7344 - val_loss: 7362948096.0000 - val_mae: 76860.2031\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 7991459328.0000 - mae: 76495.1406 - val_loss: 7050146816.0000 - val_mae: 74909.2969\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 7702893568.0000 - mae: 74636.2656 - val_loss: 6766044160.0000 - val_mae: 73061.6406\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 7429803008.0000 - mae: 72853.9375 - val_loss: 6494344704.0000 - val_mae: 71238.1875\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 7168954368.0000 - mae: 71105.6953 - val_loss: 6228972544.0000 - val_mae: 69412.4453\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 6919646208.0000 - mae: 69318.2109 - val_loss: 5972524032.0000 - val_mae: 67595.7969\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 6678090752.0000 - mae: 67572.8281 - val_loss: 5727683584.0000 - val_mae: 65821.7891\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x786a37125b70>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f'Test Mean Absolute Error: ${mae:.2f}')"
      ],
      "metadata": {
        "id": "H-at43ZlRE1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ef1896-c023-461e-d275-620411672f30"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 6237647872.0000 - mae: 63507.8750\n",
            "Test Mean Absolute Error: $63507.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key Differences Between Classification and Regression"
      ],
      "metadata": {
        "id": "AeiPDxlyRQAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target Variable: In classification, the target variable is categorical (e.g., species of iris), while in regression, the target variable is continuous (e.g., house price).\n",
        "\n",
        "Output Layer: For classification, the output layer uses a softmax activation to produce probabilities for each class. For regression, the output layer has no activation or uses a linear activation to produce a continuous value.\n",
        "Loss Function: Classification models typically use categorical cross-entropy loss, while regression models use mean squared error (MSE) or mean absolute error (MAE).\n",
        "\n",
        "Evaluation Metrics: Classification models are evaluated using accuracy, precision, recall, and F1-score. Regression models are evaluated using metrics like MSE, MAE, or R-squared."
      ],
      "metadata": {
        "id": "dKTF9pkYRI7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 5"
      ],
      "metadata": {
        "id": "MvI6x4t5R1SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "EZCN5HeZR1rr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the images to the range [0, 1]\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the images to add a channel dimension (28, 28, 1)\n",
        "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
        "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))"
      ],
      "metadata": {
        "id": "t8lNPm6lSEi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "264f30b5-ec0d-4802-a709-2ccee5052cda"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28, 1)),  # Flatten the input\n",
        "    layers.Dense(128, activation='relu'),     # Hidden layer with ReLU activation\n",
        "    layers.Dense(10, activation='softmax')    # Output layer with softmax activation for 10 classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',  # Loss function for multi-class classification\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Kr3yWe1qSIoA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "mFnPBMpCSL1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e10676b-4509-4e28-e380-af2498929824"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2924 - accuracy: 0.9162 - val_loss: 0.1659 - val_accuracy: 0.9523\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1327 - accuracy: 0.9607 - val_loss: 0.1143 - val_accuracy: 0.9678\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0915 - accuracy: 0.9731 - val_loss: 0.1075 - val_accuracy: 0.9687\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0681 - accuracy: 0.9799 - val_loss: 0.0892 - val_accuracy: 0.9737\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0526 - accuracy: 0.9841 - val_loss: 0.1001 - val_accuracy: 0.9706\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x786a375dc7f0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "4UL1haS0SU6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b03698b0-bc89-4d37-85ab-ea2a40ced87c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0848 - accuracy: 0.9736\n",
            "Test accuracy: 0.9736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Display the first 5 test images and their predicted labels\n",
        "for i in range(5):\n",
        "    plt.imshow(test_images[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(f'Predicted: {np.argmax(predictions[i])}, Actual: {test_labels[i]}')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gvuZ797sSadX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61b2df3f-9b04-4ae5-8962-7b2aacc75d21"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}