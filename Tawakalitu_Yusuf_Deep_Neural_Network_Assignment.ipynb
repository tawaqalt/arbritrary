{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk4/+eV0VQVc2UKZMVamY1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tawaqalt/arbritrary/blob/master/Tawakalitu_Yusuf_Deep_Neural_Network_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importation of Libraries"
      ],
      "metadata": {
        "id": "D9hURIxcIXeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing relevant libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "z0VapdP0IdSC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "Ka6aINoUIs_9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Problem 1] Classifying fully connected layers"
      ],
      "metadata": {
        "id": "3mOU3NffIRki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FullyConnectedLayer:\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
        "        self.B = initializer.B(self.n_nodes2)\n",
        "        self.optimizer = optimizer\n",
        "        self.HW = 0\n",
        "        self.HB = 0\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.Z = X\n",
        "        self.A = X @ self.W + self.B\n",
        "        return self.A\n",
        "\n",
        "    def backward(self, dA):\n",
        "        self.dB = np.sum(dA, axis=0)\n",
        "        self.dW = self.Z.T @ dA\n",
        "        dX = dA @ self.W.T\n",
        "        self.W, self.B = self.optimizer.update(self.W, self.B, self.dW, self.dB)\n",
        "        return dX"
      ],
      "metadata": {
        "id": "bZk26DXcIQc7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Problem 2] Classifying the initialization method"
      ],
      "metadata": {
        "id": "a82NQgBjIzS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleInitializer:\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = np.random.randn(n_nodes1, n_nodes2) * self.sigma\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
        "        return B"
      ],
      "metadata": {
        "id": "q_hj_CjgJBXz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Problem 3] Classifying optimization methods"
      ],
      "metadata": {
        "id": "VSGK826aI-S4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self, W, B, dW, dB):\n",
        "        W -= self.lr * dW / len(dW)\n",
        "        B -= self.lr * dB / len(dB)\n",
        "        return W, B"
      ],
      "metadata": {
        "id": "MfRgSaFCJJAV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Problem 4] Classifying activation functions"
      ],
      "metadata": {
        "id": "cSdDZ_z3JpMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        Z = 1 / (1 + np.exp(-self.A))\n",
        "        return Z\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dA = dout * (1 - dout)\n",
        "        return dA\n",
        "\n",
        "class Tanh:\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        Z = np.tanh(self.A)\n",
        "        return Z\n",
        "\n",
        "    def backward(self, dZ):\n",
        "        dA = dZ * (1 - np.tanh(self.A) ** 2)\n",
        "        return dA\n",
        "\n",
        "class Softmax:\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        exp_A = np.exp(A - np.max(A, axis=1, keepdims=True))\n",
        "        Z = exp_A / np.sum(exp_A, axis=1, keepdims=True)\n",
        "        return Z\n",
        "\n",
        "    def backward(self, Z, y):\n",
        "        m = len(y)\n",
        "        dA = Z - y\n",
        "        loss = -np.sum(y * np.log(Z + 1e-10)) / m\n",
        "        return dA, loss"
      ],
      "metadata": {
        "id": "FpPOAM0UJ4PI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Problem 5] ReLU class creation"
      ],
      "metadata": {
        "id": "Pl3BHg0XJwYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        Z = np.maximum(0, self.A)\n",
        "        return Z\n",
        "\n",
        "    def backward(self, dZ):\n",
        "        dA = dZ * (self.A > 0)\n",
        "        return dA"
      ],
      "metadata": {
        "id": "9K58e1-xKBQi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Problem 6] Initial value of weight"
      ],
      "metadata": {
        "id": "VdXLkiS1KGxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class XavierInitializer:\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = np.random.randn(n_nodes1, n_nodes2) * self.sigma * np.sqrt(1 / n_nodes1)\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
        "        return B\n",
        "\n",
        "class HeInitializer:\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = np.random.randn(n_nodes1, n_nodes2) * self.sigma * np.sqrt(2 / n_nodes1)\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
        "        return B"
      ],
      "metadata": {
        "id": "bcqlxtwVKN0B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Problem 7] Optimization method"
      ],
      "metadata": {
        "id": "1O-4rnxXKVAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Adagrad:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "        self.HW = 0\n",
        "        self.HB = 0\n",
        "\n",
        "    def update(self, W, B, dW, dB):\n",
        "        self.HW += dW ** 2\n",
        "        self.HB += dB ** 2\n",
        "        delta = 1e-7\n",
        "        W -= self.lr * dW / (np.sqrt(self.HW) + delta) / len(dW)\n",
        "        B -= self.lr * dB / (np.sqrt(self.HB) + delta) / len(dB)\n",
        "        return W, B"
      ],
      "metadata": {
        "id": "gvAWGW2wKX_i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Problem 8] Class completion"
      ],
      "metadata": {
        "id": "EcxdP8NWKdvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GetMiniBatch:\n",
        "    def __init__(self, X, y, batch_size=20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(X.shape[0])\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0] / self.batch_size).astype(int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        p0 = item * self.batch_size\n",
        "        p1 = item * self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]\n",
        "\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter * self.batch_size\n",
        "        p1 = self._counter * self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "metadata": {
        "id": "cHgGN3ZBELsW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetworkClassifier:\n",
        "    def __init__(self, verbose=False, epoch=1, optimizer=SGD, initialize=HeInitializer, activation=ReLU):\n",
        "        self.verbose = verbose\n",
        "        self.epoch = epoch\n",
        "        self.optimizer = optimizer\n",
        "        self.initialize = initialize\n",
        "        self.activation = activation\n",
        "        self.batch_size = 20\n",
        "        self.features = 784\n",
        "        self.n_nodes1 = 400\n",
        "        self.n_nodes2 = 200\n",
        "        self.output = 10\n",
        "        self.sigma = 0.02\n",
        "        self.lr = 0.5\n",
        "\n",
        "    def fit(self, X, y, X_val, y_val):\n",
        "        self.loss_train = []\n",
        "        self.loss_val = []\n",
        "        optimizer = self.optimizer(self.lr)\n",
        "        self.FullyConnectedLayer1 = FullyConnectedLayer(self.features, self.n_nodes1, XavierInitializer(self.sigma), optimizer)\n",
        "        self.activation1 = self.activation()\n",
        "        self.FullyConnectedLayer2 = FullyConnectedLayer(self.n_nodes1, self.n_nodes2, XavierInitializer(self.sigma), optimizer)\n",
        "        self.activation2 = self.activation()\n",
        "        self.FullyConnectedLayer3 = FullyConnectedLayer(self.n_nodes2, self.output, XavierInitializer(self.sigma), optimizer)\n",
        "        self.activation3 = Softmax()\n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
        "            for mini_X, mini_y in get_mini_batch:\n",
        "                A1 = self.FullyConnectedLayer1.forward(mini_X)\n",
        "                Z1 = self.activation1.forward(A1)\n",
        "                A2 = self.FullyConnectedLayer2.forward(Z1)\n",
        "                Z2 = self.activation2.forward(A2)\n",
        "                A3 = self.FullyConnectedLayer3.forward(Z2)\n",
        "                Z3 = self.activation3.forward(A3)\n",
        "                dA3, loss = self.activation3.backward(Z3, mini_y)\n",
        "                dZ2 = self.FullyConnectedLayer3.backward(dA3)\n",
        "                dA2 = self.activation2.backward(dZ2)\n",
        "                dZ1 = self.FullyConnectedLayer2.backward(dA2)\n",
        "                dA1 = self.activation1.backward(dZ1)\n",
        "                _ = self.FullyConnectedLayer1.backward(dA1)\n",
        "                self.loss_train.append(loss)\n",
        "            if self.verbose:\n",
        "                print(f'Epoch {i+1}/{self.epoch}, Loss: {loss:.4f}')\n",
        "        return self.loss_train\n",
        "\n",
        "    def predict(self, X):\n",
        "        A1 = self.FullyConnectedLayer1.forward(X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FullyConnectedLayer2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FullyConnectedLayer3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        return np.argmax(Z3, axis=1)\n"
      ],
      "metadata": {
        "id": "unEOEe9AEZe-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshaping\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "#Converting the data type to float\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "#Normalizing the data\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "metadata": {
        "id": "mu2wLD8GK--Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting of data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "4VS9wW8-EgUa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "y_train_one_hot = encoder.fit_transform(y_train[:, np.newaxis])\n",
        "y_val_one_hot = encoder.transform(y_val[:, np.newaxis])"
      ],
      "metadata": {
        "id": "cEvSHm6REgUb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantaiting the scratch code\n",
        "SDDNN = ScratchDeepNeuralNetworkClassifier(verbose=False, epoch=10, optimizer=SGD, initialize=HeInitializer, activation=ReLU)\n",
        "#fitting the data\n",
        "SDDNN.fit(X_train, y_train_one_hot, X_val, y_val_one_hot)\n",
        "#predicting on new data\n",
        "y_pred = SDDNN.predict(X_val)"
      ],
      "metadata": {
        "id": "z6BmPiyCEgUb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_val, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seIQwWuoLa0T",
        "outputId": "75a75e63-98fb-4d26-f2e2-8e6f9f4f4f65"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9615"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}